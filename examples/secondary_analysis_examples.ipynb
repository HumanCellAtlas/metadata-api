{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the `metadata-api` library to prepare inputs for pipelines in Green Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SmartSeq2 Pipeline\n",
    "\n",
    "1. It requires the `sample_id` and `2 fastq files` to run the SmartSeq2 pipeline:\n",
    "    - The `sample_id` should be a valid uuid string. \n",
    "    - In order to let Cromwell localize the input files during the runtime, the WDL accepts the   URL(string) to the files on a GCS bucket.\n",
    "\n",
    "2. Also **note** that although the `metadata-api` provides a handy multi-threading `dss_client` to download the files fast and peacefully, Green Box cannot transit to use that at this time, beacuse during the communication with Blue Box, there are certain steps that are logged and recorded by Green Box, which will be used for some internal retry logic. In the long-term, Green Box will migrate to use the DSS Python API `dss_client`, but for now, Green Box will keep using the functionalities in `pipeline-tools` to talk to DSS API directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ss2_fastq1_suffix = '.c7bbee4c46bbf29432862e05830c8f39.4ef74578'\n",
    "test_ss2_fastq2_suffix = '.a3a9f23d07cfc5e40a4c3a8adf3903ae.69987b3e'\n",
    "test_ss2_sample_id = 'f89a7a2e-a789-495c-bf37-11e82757cc82'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from humancellatlas.data.metadata.helpers.dss import download_bundle_metadata, dss_client\n",
    "from humancellatlas.data.metadata.api import Bundle\n",
    "from humancellatlas.data.metadata.helpers.json import as_json\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import functools\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from pipeline_tools import input_utils, dcp_utils\n",
    "from pipeline_tools.http_requests import HttpRequests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define bundle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2_bundle_id, ss2_bundle_version = '81fdd652-0820-447e-b171-c05ed6132216', '2018-08-08T120431.041734Z'\n",
    "\n",
    "dss_staging_url = 'https://dss.staging.data.humancellatlas.org/v1'  # this won't be required after migrating to use the dss_client\n",
    "\n",
    "num_workers = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare inputs\n",
    "\n",
    "To asseble a `Bundle` object, `metadata-api` requires you to provide the following parameters to the constructor:\n",
    "- `uuid: str`\n",
    "- `version: str`\n",
    "- `manifest: List[JSON]`\n",
    "- `metadata_files: Mapping[str, JSON]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Prepare `manifest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_manifest = dcp_utils.get_manifest(\n",
    "    bundle_uuid=ss2_bundle_id,\n",
    "    bundle_version=ss2_bundle_version,\n",
    "    dss_url=dss_staging_url,\n",
    "    http_requests=HttpRequests(write_dummy_files=False)\n",
    ")  # this won't be required after migrating to use the dss_client\n",
    "\n",
    "manifest = raw_manifest['bundle']['files']  # this won't be required after migrating to use the dss_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Prepare `metadata_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(item, dss_url, http_requests=HttpRequests(write_dummy_files=False)):\n",
    "    \"\"\"\n",
    "    This function borrows a lot of existing code from the `metadata-api` code base for consistency,\n",
    "    and this won't be required after migrating to use the dss_client.\n",
    "    \"\"\"\n",
    "    file_name, manifest_entry = item\n",
    "    file_uuid = manifest_entry['uuid']\n",
    "    file_version = manifest_entry['version']\n",
    "    logging.debug(\"Getting file '%s' (%s.%s) from DSS.\", file_name, file_uuid, file_version)\n",
    "    return file_name, dcp_utils.get_file_by_uuid(file_id=file_uuid, dss_url=dss_url, http_requests=http_requests)\n",
    "\n",
    "raw_metadata_files = {f[\"name\"]: f for f in manifest if f[\"indexed\"]}\n",
    "\n",
    "if num_workers == 0:\n",
    "    metadata_files = dict(\n",
    "        map(\n",
    "            functools.partial(download_file, dss_url=dss_staging_url, http_requests=HttpRequests(write_dummy_files=False)), \n",
    "            raw_metadata_files.items()\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    with ThreadPoolExecutor(num_workers) as tpe:\n",
    "        metadata_files = dict(\n",
    "        tpe.map(\n",
    "            functools.partial(download_file, dss_url=dss_staging_url, http_requests=HttpRequests(write_dummy_files=False)), \n",
    "            raw_metadata_files.items()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Assemble the `Bundle` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2_primary_bundle = Bundle(uuid=ss2_bundle_id,\n",
    "                version=ss2_bundle_version,\n",
    "                manifest=manifest,\n",
    "                metadata_files=metadata_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Get pipeline inputs by using the assembled `Bundle` object\n",
    "\n",
    "**Note** A sequence file should look like:\n",
    "```python\n",
    "SequenceFile(\n",
    "    document_id=UUID('1db5c87a-7577-4feb-8d5f-ff7dac3aaccf'),\n",
    "    file_format='fastq.gz',\n",
    "    to_processes={}, \n",
    "    manifest_entry=ManifestEntry(\n",
    "        content_type='application/gzip; dcp-type=data', \n",
    "        crc32c='string', \n",
    "        indexed=False, \n",
    "        name='R1.fastq.gz', \n",
    "        s3_etag='string', \n",
    "        sha1='string', \n",
    "        sha256='string', \n",
    "        size=int, \n",
    "        url='gs://THE_TARGET_URL_WE_WANT_HERE', \n",
    "        uuid=UUID('1db5c87a-7577-4feb-8d5f-ff7dac3aaccf'), \n",
    "        version='2018-08-08T120430.594837Z'\n",
    "    ), \n",
    "    read_index='read1', \n",
    "    lane_index=1\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => ss2_fastq_names: ['R1.fastq.gz', 'R2.fastq.gz']\n",
      " => ss2_fastq_1_url not None: True\n",
      " => ss2_fastq_2_url not None: True\n",
      " => ss2_sample_id: f89a7a2e-a789-495c-bf37-11e82757cc82\n"
     ]
    }
   ],
   "source": [
    "from humancellatlas.data.metadata import SequenceFile\n",
    "\n",
    "ss2_sequencing_output = ss2_primary_bundle.sequencing_output\n",
    "\n",
    "ss2_fastq_names = [b.manifest_entry.name for b in ss2_sequencing_output]\n",
    "\n",
    "ss2_fastq_1_url = [file for file in ss2_sequencing_output if file.read_index == 'read1'][0].manifest_entry.url\n",
    "\n",
    "ss2_fastq_2_url = [file for file in ss2_sequencing_output if file.read_index == 'read2'][0].manifest_entry.url\n",
    "\n",
    "ss2_sample_id = str(ss2_primary_bundle.sequencing_input[0].document_id)\n",
    "\n",
    "print(f' => ss2_fastq_names: {ss2_fastq_names}')\n",
    "print(f' => ss2_fastq_1_url not None: {not ss2_fastq_1_url is None}')\n",
    "print(f' => ss2_fastq_2_url not None: {not ss2_fastq_2_url is None}')\n",
    "print(f' => ss2_sample_id: {ss2_sample_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation succeeded!!\n"
     ]
    }
   ],
   "source": [
    "assert ss2_fastq_1_url.endswith(test_ss2_fastq1_suffix)\n",
    "assert ss2_fastq_2_url.endswith(test_ss2_fastq2_suffix)\n",
    "assert ss2_sample_id == test_ss2_sample_id\n",
    "\n",
    "print('Validation succeeded!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimus 10x Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Coming Soon..._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
